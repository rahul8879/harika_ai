{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas + NumPy Assignment\n",
    "\n",
    "## Goals\n",
    "- Practice creating, cleaning, and analyzing data with NumPy arrays\n",
    "- Move data into pandas DataFrames for analysis and reporting\n",
    "- Use vectorized operations, groupby, and joins\n",
    "\n",
    "## Instructions\n",
    "- Work through each section in order.\n",
    "- Show outputs for each step.\n",
    "- Add short comments where the logic is not obvious.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A: Create data with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1) Create a random dataset of 100 rows with these columns:\n",
    "# sales, units, region_id, product_id, day\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "sales = rng.integers(100, 1001, size=100)\n",
    "units = rng.integers(1, 21, size=100)\n",
    "region_id = rng.integers(1, 5, size=100)\n",
    "product_id = rng.integers(1, 7, size=100)\n",
    "day = rng.integers(1, 31, size=100)\n",
    "\n",
    "raw = np.column_stack([sales, units, region_id, product_id, day])\n",
    "raw[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2) Convert the dataset to a pandas DataFrame\n",
    "cols = [\"sales\", \"units\", \"region_id\", \"product_id\", \"day\"]\n",
    "df = pd.DataFrame(raw, columns=cols)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3) Add price = sales / units, round to 2 decimals\n",
    "\n",
    "df[\"price\"] = (df[\"sales\"] / df[\"units\"]).round(2)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 4) Add high_value flag\n",
    "\n",
    "df[\"high_value\"] = df[\"sales\"] > 800\n",
    "df[\"high_value\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B: Cleaning and validation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 5) Insert 5 missing values into sales at random positions\n",
    "missing_idx = rng.choice(df.index, size=5, replace=False)\n",
    "df.loc[missing_idx, \"sales\"] = np.nan\n",
    "\n",
    "# check missing\n",
    "(df[\"sales\"].isna().sum(), missing_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 6) Replace missing sales with median\n",
    "median_sales = df[\"sales\"].median()\n",
    "df[\"sales\"] = df[\"sales\"].fillna(median_sales)\n",
    "\n",
    "df[\"sales\"].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 7) Ensure dtypes\n",
    "\n",
    "df[\"day\"] = df[\"day\"].astype(int)\n",
    "df[\"price\"] = df[\"price\"].astype(float)\n",
    "\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C: Analysis with pandas"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 8) Total sales by region_id\n",
    "\n",
    "df.groupby(\"region_id\")[\"sales\"].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 9) Average price by product_id (descending)\n",
    "\n",
    "df.groupby(\"product_id\")[\"price\"].mean().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 10) Top 5 rows by sales\n",
    "\n",
    "df.sort_values(\"sales\", ascending=False).head(5)[\n",
    "    [\"region_id\", \"product_id\", \"sales\", \"units\", \"price\"]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 11) Region summary: total sales, total units, average price\n",
    "\n",
    "df.groupby(\"region_id\").agg(\n",
    "    total_sales=(\"sales\", \"sum\"),\n",
    "    total_units=(\"units\", \"sum\"),\n",
    "    avg_price=(\"price\", \"mean\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part D: Combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 12) Region lookup\n",
    "region_lookup = pd.DataFrame({\n",
    "    \"region_id\": [1, 2, 3, 4],\n",
    "    \"region_name\": [\"North\", \"South\", \"East\", \"West\"],\n",
    "})\n",
    "region_lookup\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 13) Product lookup\n",
    "product_lookup = pd.DataFrame({\n",
    "    \"product_id\": [1, 2, 3, 4, 5, 6],\n",
    "    \"product_name\": [\"P1\", \"P2\", \"P3\", \"P4\", \"P5\", \"P6\"],\n",
    "})\n",
    "product_lookup\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 14) Merge with lookups\n",
    "\n",
    "df_joined = df.merge(region_lookup, on=\"region_id\").merge(product_lookup, on=\"product_id\")\n",
    "df_joined.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part E: NumPy practice on arrays"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 15) From the original NumPy array\n",
    "sales_col = raw[:, 0]\n",
    "region_col = raw[:, 2]\n",
    "\n",
    "sales_mean = sales_col.mean()\n",
    "\n",
    "mean_by_region = {\n",
    "    r: sales_col[region_col == r].mean()\n",
    "    for r in np.unique(region_col)\n",
    "}\n",
    "\n",
    "max_sales = sales_col.max()\n",
    "max_row_idx = sales_col.argmax()\n",
    "\n",
    "sales_mean, mean_by_region, (max_sales, max_row_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 16) Boolean indexing\n",
    "\n",
    "filtered = raw[(raw[:, 1] >= 10) & (raw[:, 0] >= 500)]\n",
    "filtered[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part F: Challenge (optional)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 17) Pivot table of total sales by region and product\n",
    "\n",
    "pivot = df_joined.pivot_table(\n",
    "    index=\"region_name\",\n",
    "    columns=\"product_name\",\n",
    "    values=\"sales\",\n",
    "    aggfunc=\"sum\",\n",
    ")\n",
    "pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 18) Bar chart of total sales by region\n",
    "# If you are using a notebook, this will display the chart.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_joined.groupby(\"region_name\")[\"sales\"].sum().plot(kind=\"bar\")\n",
    "plt.title(\"Total Sales by Region\")\n",
    "plt.xlabel(\"Region\")\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}